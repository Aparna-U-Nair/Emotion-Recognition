{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5d9aefa",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "458277a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "import unicodedata\n",
    "from bs4 import BeautifulSoup\n",
    "from textblob import TextBlob\n",
    "import spacy\n",
    "import pickle\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16bf27b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1279e482",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30e7ff02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i feel cold</td>\n",
       "      <td>ANGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i feel the cold i can say he sends it</td>\n",
       "      <td>ANGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i remember feeling like my blood had run cold ...</td>\n",
       "      <td>ANGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i hate too is stepping outside in the cold and...</td>\n",
       "      <td>ANGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i don't think i am anti social i just don't re...</td>\n",
       "      <td>ANGER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text emotion\n",
       "0                                        i feel cold   ANGER\n",
       "1              i feel the cold i can say he sends it   ANGER\n",
       "2  i remember feeling like my blood had run cold ...   ANGER\n",
       "3  i hate too is stepping outside in the cold and...   ANGER\n",
       "4  i don't think i am anti social i just don't re...   ANGER"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(30000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"text_to_emotion.csv\")\n",
    "data.head()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cea93c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SADNESS     5000\n",
       "SURPRISE    5000\n",
       "ANGER       5000\n",
       "LOVE        5000\n",
       "JOY         5000\n",
       "FEAR        5000\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e59de7",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e41c731a",
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions = { \n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he'll've\": \"he will have\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how does\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'd've\": \"i would have\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'll've\": \"i will have\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it'll've\": \"it will have\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she'll've\": \"she will have\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so is\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they'll've\": \"they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\" u \": \" you \",\n",
    "\" ur \": \" your \",\n",
    "\" n \": \" and \",\n",
    "\"won't\": \"would not\",\n",
    "'dis': 'this',\n",
    "'bak': 'back',\n",
    "'brng': 'bring'}\n",
    "\n",
    "\n",
    "\n",
    "def cont_to_exp(x):\n",
    "    if type(x) is str:\n",
    "        for key in contractions:\n",
    "            value = contractions[key]\n",
    "            x = x.replace(key, value)\n",
    "        return x\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "\n",
    "def remove_accented_chars(x):\n",
    "    x = unicodedata.normalize('NFKD', x).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return x\n",
    "\n",
    "def make_to_base(x):\n",
    "    x = str(x)\n",
    "    x_list = []\n",
    "    doc = nlp(x)\n",
    "    \n",
    "    for token in doc:\n",
    "        lemma = token.lemma_\n",
    "        if lemma == '-PRON-' or lemma == 'be':\n",
    "            lemma = token.text\n",
    "\n",
    "        x_list.append(lemma)\n",
    "    return ' '.join(x_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12a5366f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i feel cold</td>\n",
       "      <td>ANGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i feel the cold i can say he sends it</td>\n",
       "      <td>ANGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i remember feeling like my blood had run cold ...</td>\n",
       "      <td>ANGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i hate too is stepping outside in the cold and...</td>\n",
       "      <td>ANGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i do not think i am anti social i just do not ...</td>\n",
       "      <td>ANGER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text emotion\n",
       "0                                        i feel cold   ANGER\n",
       "1              i feel the cold i can say he sends it   ANGER\n",
       "2  i remember feeling like my blood had run cold ...   ANGER\n",
       "3  i hate too is stepping outside in the cold and...   ANGER\n",
       "4  i do not think i am anti social i just do not ...   ANGER"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb9b986c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"text\"] = data[\"text\"].apply(lambda x: str(x).lower() )\n",
    "data[\"text\"] = data[\"text\"].apply(lambda x: cont_to_exp(x) )\n",
    "data[\"text\"] = data[\"text\"].apply(lambda x: remove_accented_chars(x) )\n",
    "data[\"text\"] = data[\"text\"].apply(lambda x: re.sub(r'[^\\w ]+',\"\",x))\n",
    "data[\"text\"] = data[\"text\"].apply(lambda x: make_to_base(x))\n",
    "data[\"text\"] = data[\"text\"].apply(lambda x: TextBlob(x).correct().raw_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60b671c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i feel cold</td>\n",
       "      <td>ANGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i feel the cold i can say he send it</td>\n",
       "      <td>ANGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i remember feel like my blood have run cold an...</td>\n",
       "      <td>ANGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i hate too is step outside in the cold and fee...</td>\n",
       "      <td>ANGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i do not think i am anti social i just do not ...</td>\n",
       "      <td>ANGER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text emotion\n",
       "0                                        i feel cold   ANGER\n",
       "1               i feel the cold i can say he send it   ANGER\n",
       "2  i remember feel like my blood have run cold an...   ANGER\n",
       "3  i hate too is step outside in the cold and fee...   ANGER\n",
       "4  i do not think i am anti social i just do not ...   ANGER"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e45875",
   "metadata": {},
   "source": [
    "### Load Glove vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b68ce4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vect = {}\n",
    "\n",
    "with open(\"glove/glove.6B.100d.txt\",encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        val = line.split()\n",
    "        word = val[0]\n",
    "        vect = np.asarray(val[1:])\n",
    "        glove_vect[word] = vect\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ff3bb5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glove_vect)\n",
    "glove_vect.get(\"theeeeeeee\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd271bf",
   "metadata": {},
   "source": [
    "### Text to glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "83e9d96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_shape = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e4de39ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vec(row):\n",
    "    arr = np.zeros(vec_shape)\n",
    "    text = str(row).split()\n",
    "    for t in text:\n",
    "        try:\n",
    "            vec = glove_vect.get(t).astype(float)\n",
    "            arr = arr +vec\n",
    "        except:\n",
    "            pass\n",
    "    arr.reshape(1,-1)[0] # 1d to 2d array by reshape, hence take [0]\n",
    "    return arr/len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "65f895e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"vec\"] = data[\"text\"].apply(lambda x: get_vec(x)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331d8ad3",
   "metadata": {},
   "source": [
    "###  Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db12cbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"vec\"]\n",
    "y = data[\"emotion\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "46eebad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(30000,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4f3622ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 100)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(30000,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.concatenate(X,axis =0).reshape(-1,vec_shape)\n",
    "X.shape\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "38fb5cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d73344d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24000, 100)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6000, 100)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(24000,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6000,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "X_test.shape\n",
    "y_train.shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcba350",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "480e1762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ANGER       0.68      0.65      0.66      1000\n",
      "        FEAR       0.71      0.68      0.70      1000\n",
      "         JOY       0.73      0.74      0.74      1000\n",
      "        LOVE       0.79      0.83      0.81      1000\n",
      "     SADNESS       0.73      0.72      0.73      1000\n",
      "    SURPRISE       0.76      0.79      0.78      1000\n",
      "\n",
      "    accuracy                           0.74      6000\n",
      "   macro avg       0.74      0.74      0.74      6000\n",
      "weighted avg       0.74      0.74      0.74      6000\n",
      "\n",
      "[[649  88  77  40  94  52]\n",
      " [ 80 683  56  50  62  69]\n",
      " [ 69  38 743  54  40  56]\n",
      " [ 37  31  37 831  32  32]\n",
      " [ 76  80  51  37 721  35]\n",
      " [ 41  45  50  37  36 791]]\n"
     ]
    }
   ],
   "source": [
    "#LogReg\n",
    "\n",
    "clf = LogisticRegression(solver = 'liblinear', multi_class='auto')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3028365f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ANGER       0.69      0.64      0.67      1000\n",
      "        FEAR       0.72      0.69      0.70      1000\n",
      "         JOY       0.73      0.75      0.74      1000\n",
      "        LOVE       0.78      0.83      0.80      1000\n",
      "     SADNESS       0.73      0.73      0.73      1000\n",
      "    SURPRISE       0.76      0.79      0.78      1000\n",
      "\n",
      "    accuracy                           0.74      6000\n",
      "   macro avg       0.74      0.74      0.74      6000\n",
      "weighted avg       0.74      0.74      0.74      6000\n",
      "\n",
      "[[641  85  79  47  97  51]\n",
      " [ 74 685  60  54  61  66]\n",
      " [ 63  38 749  50  41  59]\n",
      " [ 36  31  34 830  34  35]\n",
      " [ 71  71  53  38 729  38]\n",
      " [ 38  41  52  45  31 793]]\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "clf = LinearSVC()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0d3f1496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SADNESS     5000\n",
       "SURPRISE    5000\n",
       "ANGER       5000\n",
       "LOVE        5000\n",
       "JOY         5000\n",
       "FEAR        5000\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b816065",
   "metadata": {},
   "source": [
    "### Model Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ae4b0bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pickle'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pickle.dump(clf, open('model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090cd2ab",
   "metadata": {},
   "source": [
    "### Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5402d396",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'i am so happy. thanks a lot'\n",
    "def get_pred(x):\n",
    "    x = str(x).lower()\n",
    "    x =  cont_to_exp(x)\n",
    "    x =  re.sub(r'[^\\w ]+',\"\",x)\n",
    "    x = remove_accented_chars(x)\n",
    "    vec = get_vec(x).reshape(-1, vec_shape)\n",
    "    \n",
    "    emotion = clf.predict(vec)\n",
    "    \n",
    "    return emotion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7d12db46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['JOY'], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pred(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557f0302",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
